{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11322103,"sourceType":"datasetVersion","datasetId":7081531}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install huggingface_hub","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:51:57.094073Z","iopub.execute_input":"2025-04-12T08:51:57.094480Z","iopub.status.idle":"2025-04-12T08:52:01.642131Z","shell.execute_reply.started":"2025-04-12T08:51:57.094428Z","shell.execute_reply":"2025-04-12T08:52:01.641231Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.29.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.17.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.12.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2025.1.31)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:52:06.317024Z","iopub.execute_input":"2025-04-12T08:52:06.317312Z","iopub.status.idle":"2025-04-12T08:52:09.616985Z","shell.execute_reply.started":"2025-04-12T08:52:06.317290Z","shell.execute_reply":"2025-04-12T08:52:09.615940Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.11.0a2)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.29.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from huggingface_hub import login\n\n\nhf_token = \"\"\nlogin(hf_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:52:19.112261Z","iopub.execute_input":"2025-04-12T08:52:19.112633Z","iopub.status.idle":"2025-04-12T08:52:19.190163Z","shell.execute_reply.started":"2025-04-12T08:52:19.112602Z","shell.execute_reply":"2025-04-12T08:52:19.189525Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import wandb\n\nwb_token = \"\"\n\nwandb.login(key=wb_token)\nrun = wandb.init(\n    project='Fine-tune-DeepSeek-R1-Distill-Llama-8B on PAssFinder', \n    job_type=\"training\", \n    anonymous=\"allow\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:52:21.770105Z","iopub.execute_input":"2025-04-12T08:52:21.770410Z","iopub.status.idle":"2025-04-12T08:52:36.629986Z","shell.execute_reply.started":"2025-04-12T08:52:21.770387Z","shell.execute_reply":"2025-04-12T08:52:36.629118Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchishti055\u001b[0m (\u001b[33mchishti055-north-south-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.1"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250412_085230-lx0vjtwo</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/chishti055-north-south-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20PAssFinder/runs/lx0vjtwo' target=\"_blank\">wise-capybara-28</a></strong> to <a href='https://wandb.ai/chishti055-north-south-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20PAssFinder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/chishti055-north-south-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20PAssFinder' target=\"_blank\">https://wandb.ai/chishti055-north-south-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20PAssFinder</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/chishti055-north-south-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20PAssFinder/runs/lx0vjtwo' target=\"_blank\">https://wandb.ai/chishti055-north-south-university/Fine-tune-DeepSeek-R1-Distill-Llama-8B%20on%20PAssFinder/runs/lx0vjtwo</a>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"pip install unsloth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T08:54:41.245656Z","iopub.execute_input":"2025-04-12T08:54:41.245935Z","iopub.status.idle":"2025-04-12T08:58:11.349826Z","shell.execute_reply.started":"2025-04-12T08:54:41.245914Z","shell.execute_reply":"2025-04-12T08:58:11.348868Z"}},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.3.19-py3-none-any.whl.metadata (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.3.17 (from unsloth)\n  Downloading unsloth_zoo-2025.3.17-py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.5.1+cu121)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nCollecting bitsandbytes (from unsloth)\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.2)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.18-py3-none-any.whl.metadata (9.2 kB)\nCollecting transformers!=4.47.0,>=4.46.1 (from unsloth)\n  Downloading transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.3.1)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.2.1)\nCollecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth)\n  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.14.0)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.29.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.31.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.20.1+cu121)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.11.12)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->unsloth) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nCollecting huggingface_hub (from unsloth)\n  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.0)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.10/dist-packages (from triton>=3.0.0->unsloth) (75.1.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (13.9.4)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.3.17->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.3.17->unsloth) (11.0.0)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->unsloth) (8.5.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (4.4.1)\nCollecting typing-extensions>=3.7.4.3 (from huggingface_hub->unsloth)\n  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.18.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2025.1.31)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.19.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->unsloth) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2025.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.17.0)\nDownloading unsloth-2025.3.19-py3-none-any.whl (192 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.7/192.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading transformers-4.51.2-py3-none-any.whl (10.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.4/481.4 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.3.17-py3-none-any.whl (127 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.8/127.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.29.post3-cp310-cp310-manylinux_2_28_x86_64.whl (43.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.18-py3-none-any.whl (123 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nInstalling collected packages: triton, nvidia-cusparselt-cu12, typing-extensions, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface_hub, tyro, nvidia-cusolver-cu12, torch, cut_cross_entropy, transformers, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.12.2\n    Uninstalling typing_extensions-4.12.2:\n      Successfully uninstalled typing_extensions-4.12.2\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.29.0\n    Uninstalling huggingface-hub-0.29.0:\n      Successfully uninstalled huggingface-hub-0.29.0\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu121\n    Uninstalling torch-2.5.1+cu121:\n      Successfully uninstalled torch-2.5.1+cu121\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.20.1+cu121\n    Uninstalling torchvision-0.20.1+cu121:\n      Successfully uninstalled torchvision-0.20.1+cu121\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\nlangchain 0.3.12 requires async-timeout<5.0.0,>=4.0.0; python_version < \"3.11\", but you have async-timeout 5.0.1 which is incompatible.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 25.2.0 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\ntorchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.5 cut_cross_entropy-25.1.1 huggingface_hub-0.30.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 shtab-1.7.1 torch-2.6.0 torchvision-0.21.0 transformers-4.51.2 triton-3.2.0 trl-0.15.2 typing-extensions-4.13.2 tyro-0.9.18 unsloth-2025.3.19 unsloth_zoo-2025.3.17 xformers-0.0.29.post3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from unsloth import FastLanguageModel\n\nmax_seq_length = 2048 \ndtype = None \nload_in_4bit = True\n\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/DeepSeek-R1-Distill-Llama-8B\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    token = hf_token, \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:01:28.669849Z","iopub.execute_input":"2025-04-12T09:01:28.670164Z","iopub.status.idle":"2025-04-12T09:02:52.813994Z","shell.execute_reply.started":"2025-04-12T09:01:28.670135Z","shell.execute_reply":"2025-04-12T09:02:52.812768Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\nUnsloth: Failed to patch Gemma3ForConditionalGeneration.\n🦥 Unsloth Zoo will now patch everything to make training faster!\n==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46cfed9b3de24d9a86f9c704ce9a3b90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84950525468f455fa7064c09d9309292"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/53.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab4c55130a804512a16f8aed54f342c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"248dfc267d774979971461c90cf70005"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d88126bfc5ea49a4bcfbf550ff6d989e"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"pip install datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:08:41.394265Z","iopub.execute_input":"2025-04-12T09:08:41.394631Z","iopub.status.idle":"2025-04-12T09:08:45.168278Z","shell.execute_reply.started":"2025-04-12T09:08:41.394599Z","shell.execute_reply":"2025-04-12T09:08:45.167260Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:08:48.020923Z","iopub.execute_input":"2025-04-12T09:08:48.021233Z","iopub.status.idle":"2025-04-12T09:08:48.026385Z","shell.execute_reply.started":"2025-04-12T09:08:48.021209Z","shell.execute_reply":"2025-04-12T09:08:48.025507Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"/kaggle/input/med-data\", split = \"train[0:500]\",trust_remote_code=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:08:50.371030Z","iopub.execute_input":"2025-04-12T09:08:50.371316Z","iopub.status.idle":"2025-04-12T09:08:50.697678Z","shell.execute_reply.started":"2025-04-12T09:08:50.371295Z","shell.execute_reply":"2025-04-12T09:08:50.696971Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11bf41fa8a724bee88154007c4f485a4"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r=16,  \n    target_modules=[\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\",\n    ],\n    lora_alpha=16,\n    lora_dropout=0,  \n    bias=\"none\",  \n    use_gradient_checkpointing=\"unsloth\",  # True or \"unsloth\" for very long context\n    random_state=3407,\n    use_rslora=False,  \n    loftq_config=None,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:08:54.519482Z","iopub.execute_input":"2025-04-12T09:08:54.519797Z","iopub.status.idle":"2025-04-12T09:09:00.677939Z","shell.execute_reply.started":"2025-04-12T09:08:54.519773Z","shell.execute_reply":"2025-04-12T09:09:00.677193Z"}},"outputs":[{"name":"stderr","text":"Unsloth 2025.3.19 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom unsloth import is_bfloat16_supported\n\ndef no_formatting(data):\n    return [str(data)]\n\n\ndef preprocess_function(examples):\n    concatenated_text = [\n        f\"Brand: {brand} ({generic}) | Strength: {strength} | Dosage Form: {form} | \"\n        f\"Manufacturer: {manufacturer} | Mode of Action: {moa} | Dosage: {dosage} | \"\n        f\"Contraindications: {contraindications} | Side Effects: {side_effects} | \"\n        f\"Precautions: {precautions} | Overdose Effects: {overdose} | Drug Classes: {classes}\"\n        for brand, generic, strength, form, manufacturer, moa, dosage, \n            contraindications, side_effects, precautions, overdose, classes in zip(\n                examples[\"brand_name\"],\n                examples[\"generic_name\"],\n                examples[\"strength\"],\n                examples[\"dosage_form\"],\n                examples[\"manufacturer\"],\n                examples[\"mode_of_action\"],\n                examples[\"dosage\"],\n                examples[\"contraindications\"],\n                examples[\"side_effects\"],\n                examples[\"precautions\"],\n                examples[\"overdose_effects\"],\n                examples[\"drug_classes\"]\n        )\n    ]\n    return {\"text\": concatenated_text}\n\ndataset = dataset.map(preprocess_function, batched=True)\n\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    train_dataset=dataset,\n    dataset_text_field=\"text\",  # Now using the concatenated text field\n    max_seq_length=max_seq_length,\n    dataset_num_proc=2,\n    formatting_func=no_formatting,  # Add this line to use no formatting\n    args=TrainingArguments(\n        per_device_train_batch_size=2,\n        gradient_accumulation_steps=4,\n        num_train_epochs=1,\n        warmup_steps=5,\n        max_steps=60,\n        learning_rate=2e-4,\n        fp16=not is_bfloat16_supported(),\n        bf16=is_bfloat16_supported(),\n        logging_steps=10,\n        optim=\"adamw_8bit\",\n        weight_decay=0.01,\n        lr_scheduler_type=\"linear\",\n        seed=3407,\n        output_dir=\"outputs\",\n    ),\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:09:04.068964Z","iopub.execute_input":"2025-04-12T09:09:04.069270Z","iopub.status.idle":"2025-04-12T09:09:06.781603Z","shell.execute_reply.started":"2025-04-12T09:09:04.069245Z","shell.execute_reply":"2025-04-12T09:09:06.780867Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/450 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3b18fd6cbcc42049f59c894252d71ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/450 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69fa82dd251c46cc9f26726e23cc9742"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T09:09:13.605767Z","iopub.execute_input":"2025-04-12T09:09:13.606086Z","iopub.status.idle":"2025-04-12T10:05:02.644280Z","shell.execute_reply.started":"2025-04-12T09:09:13.606060Z","shell.execute_reply":"2025-04-12T10:05:02.643434Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 450 | Num Epochs = 3 | Total steps = 60\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 54:17, Epoch 2/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.881500</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.463700</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.331600</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.135800</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.003400</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.932100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"model.save_pretrained(\"MedExpertLLM\")\ntokenizer.save_pretrained(\"MedExpertLLM\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T07:59:36.096373Z","iopub.execute_input":"2025-04-12T07:59:36.096681Z","iopub.status.idle":"2025-04-12T07:59:36.855931Z","shell.execute_reply.started":"2025-04-12T07:59:36.096657Z","shell.execute_reply":"2025-04-12T07:59:36.855245Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"('MedExpertLLM/tokenizer_config.json',\n 'MedExpertLLM/special_tokens_map.json',\n 'MedExpertLLM/tokenizer.json')"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"prompt_style = \"\"\" \nWrite a response that appropriately completes the request and just give accurate response.\n\n### Instruction:\nYou are an expert with advanced knowledge in suggesting medicine based on symptoms , diagnostics, and provide with correct solution with explanation . Please give the exact answer and suggest the medicines user gives us .. \n. \n\n### Question:\n{}\n\n### Response:\n<think>{}\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T11:51:14.867199Z","iopub.execute_input":"2025-04-12T11:51:14.867569Z","iopub.status.idle":"2025-04-12T11:51:14.871814Z","shell.execute_reply.started":"2025-04-12T11:51:14.867538Z","shell.execute_reply":"2025-04-12T11:51:14.871002Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"question = \"\"\" what is the generic name for 3 Bion Tablet ?\n\"\"\"\n\n\nFastLanguageModel.for_inference(model) \ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1200,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T10:06:30.103203Z","iopub.execute_input":"2025-04-12T10:06:30.103584Z","iopub.status.idle":"2025-04-12T10:07:03.107435Z","shell.execute_reply.started":"2025-04-12T10:06:30.103546Z","shell.execute_reply":"2025-04-12T10:07:03.106437Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, so I need to figure out the generic name for 3 Bion Tablet. First, I should understand what the product is. The name \"3 Bion Tablet\" sounds like a medication that's available in tablet form. The \"3\" might stand for the number of active ingredients or dosage form. \"Bion\" could be a brand name or a specific formulation. \n\nI should consider that sometimes brand names and generic names are different. The generic name is the chemical name of the active ingredient, while the brand name is the product name given by the manufacturer. So, I need to find the chemical name of the active ingredient in 3 Bion Tablet.\n\nI should look up \"3 Bion Tablet\" online to see if there's a generic name associated with it. If I search for \"3 Bion Tablet,\" I might find the manufacturer's website or other reliable sources that provide the active ingredient. Alternatively, I could search for \"3 Bion Tablet active ingredient\" or \"3 Bion Tablet composition\" to find the chemical name.\n\nSuppose after searching, I find that the active ingredient is \"Bambuterol Hydrochloride.\" That would mean the generic name for 3 Bion Tablet is \"Bambuterol Hydrochloride Tablet.\" I should also confirm if there are other active ingredients or if it's a combination medication. If it's a combination, the generic name might include all active ingredients, like \"Bambuterol Hydrochloride + Levalbuterol Hydrochloride Tablet,\" but usually, the brand name is for a single active ingredient unless specified otherwise.\n\nI should also consider if the dosage form affects the generic name. Since it's a tablet, the generic name would typically be \"Tablet,\" but sometimes it's omitted for brevity. Therefore, the generic name would simply be \"Bambuterol Hydrochloride.\"\n\nIf I'm unsure, I might check a reliable drug information source like a pharmacopoeia or a medical dictionary. If I can't find it there, I could look for manufacturer information or contact the drug manufacturer directly for the generic name.\n\nIn summary, after researching and identifying the active ingredient, the generic name for 3 Bion Tablet is determined to be \"Bambuterol Hydrochloride Tablet.\"\n</think>\n\nThe generic name for 3 Bion Tablet is **Bambuterol Hydrochloride Tablet**.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"question = \"\"\" what are the medicnes for the asthmatic patients ?\n\"\"\"\n\n\nFastLanguageModel.for_inference(model) \ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1200,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T10:08:16.964856Z","iopub.execute_input":"2025-04-12T10:08:16.965169Z","iopub.status.idle":"2025-04-12T10:09:22.096675Z","shell.execute_reply.started":"2025-04-12T10:08:16.965148Z","shell.execute_reply":"2025-04-12T10:09:22.095520Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, I need to figure out the best medicines for asthmatic patients. First, I should understand what asthma is. Asthma is a chronic respiratory disease where the airways become inflamed and narrow, making it hard to breathe. There are different types of asthma—intermittent, persistent, and severe. Medicines vary depending on the type and severity of asthma.\n\nI remember that short-acting beta-agonists like albuterol are commonly used to relieve symptoms during an attack. They work quickly by relaxing the muscles around the airways. Long-acting beta-agonists like formoterol are used to prevent symptoms over time. Inhaled corticosteroids like beclometasone are used to reduce inflammation in the airways. Some inhalers combine a corticosteroid with a long-acting beta-agonist, like Advair or Seretide. Leukotriene modifiers like montelukast help reduce the inflammation response.\n\nThere are also medications to reduce the immune response, like omalizumab, which is used in severe asthma. Anti-inflammatory medications like ibuprofen can be used in acute attacks but should be used cautiously in asthmatics. Oxygen therapy is used in severe cases. Some patients require special medications like theophylline or erythromycin. For severe asthma, theophylline should be used under strict medical supervision. In severe cases, corticosteroids may be used orally or by inhalation. For patients who don’t respond to standard treatments, biologic therapies like anti-IL5 monoclonal antibodies may be considered. These include medications like dupilumab and benralizumab. Some patients may also benefit from immunotherapy, a treatment that reduces the immune response to allergens. This therapy is most effective in patients with allergic asthma and is given under strict medical supervision. For patients who experience frequent exacerbations, inhaled antibiotics like azithromycin may be prescribed. In very severe cases, oral corticosteroids are sometimes used for a short period to reduce inflammation. Patients should consult their healthcare provider before starting any new medication to ensure it's appropriate for their condition and health status. It’s also important to follow the instructions from the healthcare provider regarding the correct dose and frequency of medications. Patients should avoid certain medications like β-blockers unless prescribed by a healthcare provider. The management of asthma is a shared responsibility between the patient and the healthcare provider. Regular monitoring of symptoms and lung function is essential, and treatment should be adjusted to meet the patient’s individual needs.\n</think>\n\nThe management of asthma is a shared responsibility between the patient and the healthcare provider. Here is a structured approach to the treatment of asthmatic patients:\n\n1. **Understanding Asthma**: Asthma is a chronic respiratory disease characterized by airway inflammation and narrowing, affecting the ability to breathe. It can be classified into intermittent, persistent, and severe types, each requiring specific treatment approaches.\n\n2. **Drug Classes**:\n   - **Short-acting Beta-agonists (SABA)**: Used for acute symptom relief, such as albuterol, which relaxes airway muscles during an attack.\n   - **Long-acting Beta-agonists (LABA)**: Used for long-term control, such as formoterol, to prevent symptoms.\n   - **Inhaled Corticosteroids (ICS)**: Reduce airway inflammation, commonly used with LABA, such as beclometasone.\n   - **Leukotriene Modifiers**: Used for long-term control, such as montelukast, to reduce inflammatory responses.\n   - **Combination inhalers**: Combines a corticosteroid with a long-acting beta-agonist, like Advair or Seretide.\n   - **Anti-IL5 Monoclonal Antibodies**: Used in severe asthma, such as dupilumab and benralizumab.\n   - **Inhaled Antibiotics**: Used for frequent exacerbations, such as azithromycin.\n   - **Oral Corticosteroids**: Used short-term to reduce inflammation, typically under medical supervision.\n   - **Theophylline**: Used under strict supervision for severe asthma control.\n   - **Immunotherapy**: Reduces immune response to allergens, most effective in allergic asthma, administered under supervision.\n\n3. **Patient Considerations**: Patients should consult healthcare providers before starting new medications, follow dosing instructions, and avoid β-blockers unless prescribed. Regular monitoring of symptoms and lung function is essential, with treatment adjusted to individual needs.\n\n4. **Conclusion**: Asthma treatment requires a tailored approach, with regular monitoring and adjustment under medical supervision.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"question = \"\"\" which medicines contain Cefixime Trihydrate ?\n\"\"\"\n\n\nFastLanguageModel.for_inference(model) \ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1200,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T10:11:32.818659Z","iopub.execute_input":"2025-04-12T10:11:32.819005Z","iopub.status.idle":"2025-04-12T10:12:55.174027Z","shell.execute_reply.started":"2025-04-12T10:11:32.818984Z","shell.execute_reply":"2025-04-12T10:12:55.173133Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nAlright, so I need to figure out which medicines contain Cefixime Trihydrate. First, I should understand what Cefixime Trihydrate is. I know that Cefixime is an antibiotic used to treat infections caused by bacteria. It belongs to a class called third-generation cephalosporins. These are broad-spectrum antibiotics that can treat a variety of bacterial infections, including infections of the ear, nose, throat, skin, and lower respiratory tract.\n\nCefixime is usually taken orally, in the form of a tablet or liquid suspension. It works by inhibiting bacterial cell wall synthesis. The bacteria that are susceptible to Cefixime will be killed or stopped from multiplying. This makes it effective against a wide range of bacterial infections caused by both Gram-positive and Gram-negative bacteria.\n\nCefixime is commonly used to treat infections such as bronchitis, pneumonia, sinusitis, otitis media, and gonorrhoea. It is also used in combination with other antibiotics to treat typhoid fever and cholecystitis.\n\nCefixime Trihydrate is a trihydrate form of Cefixime. The \"Trihydrate\" refers to the molecule having three water molecules attached to the antibiotic molecule. This form is usually available in tablet form and is rapidly absorbed after oral administration.\n\nNow, to find out which medicines contain Cefixime Trihydrate, I can look up the drug classes or specific brands that include Cefixime Trihydrate as an active ingredient. Some common brands of Cefixime Trihydrate include:\n- Cefix-CD Tablet (Cefixime Trihydrate) by ACI Limited\n- Cefixime Trihydrate Tablet by ACI Limited\n- Cefixime Trihydrate Tablet by ACI Limited\n- Cefix-TR Tablet (Cefixime Trihydrate) by ACI Limited\n- Cefix-TR Tablet (Cefixime Trihydrate) by ACI Limited\n- Cefix-TR Tablet (Cefixime Trihydrate) by ACI Limited\n- Cefix-TR Tablet (Cefixime Trihydrate) by ACI Limited\n- Cefix-TR Tablet (Cefixime Trihydrate) by ACI Limited\n- Cefix-TR Tablet (Cefixime Trihydrate) by ACI Limited\n\nThese brands are available in tablet form and contain Cefixime Trihydrate as the active ingredient. It's important to note that the dosage and duration of treatment should be determined by the physician based on the severity of the infection and the patient's clinical status. Cefixime should be administered with caution to patients with a history of hypersensitivity to cephalosporin antibiotics. Cefixime should not be administered to patients with a history of severe reactions to penicillins. Cefixime should be given with caution to patients who have demonstrated some form of allergy, whether or not to penicillins. As with all drugs, Cefixime should be used with caution in patients with hepatic and renal impairment. Cefixime should be administered with caution in patients with evidence of hepatic disease. Cefixime is contraindicated in patients with known hypersensitivity to Cefixime or to any other cephalosporin antibiotic.\n\nIn case of an allergic reaction, Cefixime should be discontinued and appropriate countermeasures should be instituted. If an allergic reaction is suspected, the patient should be advised to notify their physician of this reaction and to discontinue Cefixime and seek immediate medical attention. If the reaction continues despite discontinuation of Cefixime, the physician should consider the possibility of an allergic reaction to other drugs and institute appropriate diagnostic measures. If an allergic reaction occurs with Cefixime, the patient should not be re-exposed to Cefixime or to any other cephalosporin antibiotic in the future. Use caution in patients with a history of non-cephalosporin penicillin allergy. There have been reports of transient hepatitis and cholestatic jaundice occurring in patients treated with cephalosporins. Cefixime should be given with caution in patients with a history of hepatic disease. There have been no reports of hepatic failure or hepatic necrosis in patients treated with Cefixime. As with other cephalosporins, rare instances of transient hepatitis have occurred in patients treated with Cefixime. Cefixime should be used with caution in patients with a history of hepatic disease. Cefixime should be used with caution in patients with evidence of hepatic disease. As with other cephalosporins, rare instances of transient hepatitis have occurred in patients treated with Cefixime. Cefixime should be used with caution in patients with a history of hepatic disease. Cefixime should be used with caution in patients with evidence of hepatic disease. As with other cephalosporins, rare instances of transient hepatitis have occurred in patients treated with Cefixime. Cefixime should be used with caution in patients with a history of hepatic disease. Cefixime should be used with caution in patients with evidence of hepatic disease. As with other cephalosporins, rare instances of transient hepatitis have occurred in patients treated with Cefixime. Cefixime should be used with caution in patients with a history of hepatic disease. Cefixime should be used with caution in patients with evidence of hepatic disease. As with other cephalosporins, rare instances of transient hepatitis have occurred in patients treated with Cefixime. Cefixime should be used with caution in patients with a history of hepatic disease. Cefixime should be used with caution in patients\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"question = \"\"\" which local company produces 3-C Powder for Suspension ?\n\"\"\"\n\n\nFastLanguageModel.for_inference(model) \ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1200,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T11:56:48.492002Z","iopub.execute_input":"2025-04-12T11:56:48.492343Z","iopub.status.idle":"2025-04-12T11:58:10.244403Z","shell.execute_reply.started":"2025-04-12T11:56:48.492308Z","shell.execute_reply":"2025-04-12T11:58:10.242977Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, so the user is asking which local company produces 3-C Powder for Suspension. I need to provide an accurate and helpful response. First, I should verify the information to ensure it's up-to-date. I recall that 3-C Powder is an antiviral medication used for the treatment of influenza (flu). It's also known as oseltamivir phosphate. I should check if there are any local manufacturers of this medication.\n\nUpon checking, I find that several pharmaceutical companies in Bangladesh produce oseltamivir phosphate under different brand names. One of the prominent companies is ACME Laboratories Ltd. They manufacture this medication under the brand name \"ACME-C Powder for Suspension.\" This is a reliable source of this antiviral medication in Bangladesh.\n\nI should also consider the dosage form and strength of this medication. ACME-C is available as a powder for suspension and is used for oral administration. The recommended dosage for adults and children over 12 years is 75 mg twice daily for five days. The recommended dosage for children 6 to 11 years of age is 3 mg/kg body weight twice daily for five days. The total daily dose should not exceed 150 mg per day.\n\nIt's also important to note the side effects and precautions associated with this medication. Common side effects include nausea, vomiting, diarrhea, stomach pain, headache, dizziness, and rash. It should be administered with caution to patients with known hypersensitivity to oseltamivir phosphate or to any of the excipients of ACME-C Powder for Suspension. It should not be used in patients with known hypersensitivity to influenza A virus neuraminidase (N1) and N2. It should also be used with caution in patients with a history of severe hypersensitivity reactions to other medications. The safety and efficacy of ACME-C Powder for Suspension in pediatric patients below 6 years of age have not been established.\n\nIn addition to the above information, I should also provide guidance on how to prepare the suspension. The suspension should be prepared by dissolving 1-2 teaspoonful of ACME-C Powder for Suspension in a glass of water. If necessary, more water may be added to a total of 150 ml of liquid. The mixture should be stirred well and the dose should be taken immediately after dissolving. If the mixture is not taken immediately, it should be discarded and re-prepared when needed.\n\nIt's also important to remind the user to consult their healthcare provider if the patient is currently taking any other medication by mouth, especially beta-lactam antibiotics (e.g., penicillins, cephalosporins), probenecid (a uricosuric agent), anticholinergics, antihistaminics, antiparkinsonians, muscle relaxants, anticoagulants, and drugs containing sodium. There have been reports of increased gastrointestinal tract pH and enhanced absorption of certain beta-lactam antibiotics by concurrent administration of oseltamivir phosphate. Therefore, there is a potential for increased plasma concentrations of these beta-lactam antibiotics and an increase in untoward effects.\n\nIn conclusion, ACME Laboratories Ltd. is a reliable manufacturer of ACME-C Powder for Suspension in Bangladesh, which is an effective antiviral medication for the treatment of influenza. It is important to follow the dosage instructions carefully and to consult a healthcare provider if there are any pre-existing medical conditions or if the patient is currently taking other medications.\n</think>\n\n**Answer:**\n\nACME Laboratories Ltd. produces ACME-C Powder for Suspension, an effective antiviral medication for the treatment of influenza. Here are the key details about this medication:\n\n- **Dosage Form and Strength:** Available as a powder for suspension.\n- **Dosage:** \n  - Recommended for adults and children over 12 years: 75 mg twice daily for five days.\n  - Recommended for children 6 to 11 years of age: 3 mg/kg body weight twice daily for five days. The total daily dose should not exceed 150 mg per day.\n- **Side Effects:** Common side effects include nausea, vomiting, diarrhea, stomach pain, headache, dizziness, and rash.\n- **Precautions:** Should be administered with caution to patients with known hypersensitivity to oseltamivir phosphate or to any of the excipients of ACME-C Powder for Suspension. It should not be used in patients with known hypersensitivity to influenza A virus neuraminidase (N1) and N2. Caution should also be exercised in patients with a history of severe hypersensitivity reactions to other medications.\n- **Contraindications:** Should not be used in patients with known hypersensitivity to influenza A virus neuraminidase (N1) and N2.\n- **Preparation:** The suspension should be prepared by dissolving 1-2 teaspoonful of ACME-C Powder for Suspension in a glass of water. If necessary, more water may be added to a total of 150 ml of liquid. The mixture should be stirred well and the dose should be taken immediately after dissolving. If the mixture is not taken immediately, it should be discarded and re-prepared when needed.\n- **Drug Classes:** None.\n- **Manufacturer:** ACME Laboratories Ltd.\n- **Mode of Action:** None.\n- **Dosage Form:** Powder for Suspension.\n- **Contraindications:** None.\n- **Side Effects:** None.\n- **Precautions:** None.\n- **Overdose Effects:** None.\n- **Drug Classes:** None.\n- **Manufacturer:** ACME Laboratories Ltd.\n- **Mode of Action:** None.\n- **Dosage Form:** Powder for Suspension.\n- **Contraindications:** None.\n- **Side Effects:** None.\n- **Precautions:** None.\n- **Overdose Effects:** None.\n- **Drug Classes:** None.\n- **Manufacturer\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"Levofloxacin Hemihydrate","metadata":{}},{"cell_type":"code","source":"question = \"\"\" which medicines contain Levofloxacin Hemihydrate ?\n\"\"\"\n\n\nFastLanguageModel.for_inference(model) \ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1200,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T10:45:11.211978Z","iopub.execute_input":"2025-04-12T10:45:11.212272Z","iopub.status.idle":"2025-04-12T10:46:33.820106Z","shell.execute_reply.started":"2025-04-12T10:45:11.212251Z","shell.execute_reply":"2025-04-12T10:46:33.819001Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, so I need to figure out which medicines contain Levofloxacin Hemihydrate. First, I should understand what Levofloxacin Hemihydrate is. I know that Levofloxacin is an antibiotic used to treat infections caused by bacteria. It's a third-generation fluoroquinolone antibiotic, similar to other antibiotics like Ciprofloxacin and Ofloxacin. The \"Hemihydrate\" part probably refers to the form of the drug, meaning it's in a hydrated form, but I'm not entirely sure about the difference between that and other forms like Levofloxacin Anhydrous or Levofloxacin Tablet.\n\nNext, I should think about brand names of Levofloxacin. I recall that Levofloxacin is sold under several brand names in different countries. In India, for example, it's sold as Levofloxacin Tablet by companies like ACME Laboratories Ltd. and ACME Laboratories Ltd. (Dangal Division). In the United States, it's sold as Levofloxacin Tablet by Janssen Pharmaceuticals Inc., and also as a intravenous infusion by the same company. In China, it's sold under the brand name Leva-MR by Nanjing Pharmaceutical Co. Ltd. and by other companies like Shanghai Pharmaceuticals Co. Ltd. In the UK, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Canada, it's sold as Levaquin by Janssen Pharmaceuticals Inc. and by other companies like Acta Pharmaceuticals Ltd. In South Africa, it's sold as Levofloxacin by Janssen Pharmaceuticals Ltd. and by other companies like ACME Laboratories Ltd. and Ambee Pharmaceuticals Ltd. In Brazil, it's sold as Levofloxacin by Janssen Pharmaceuticals Ltd. and by other companies like Eurofarma Laboratorios Ltd. and Laboratorios Biológicos Ltd. In Germany, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In the Philippines, it's sold as Levaquin by Janssen Pharmaceuticals Inc. and by other companies like Acta Pharmaceuticals Ltd. In Vietnam, it's sold as Levaquin by Janssen Pharmaceuticals Ltd. and by other companies like Acta Pharmaceuticals Ltd. In Japan, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Taiwan, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Hong Kong, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Singapore, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Malaysia, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Thailand, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Indonesia, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Australia, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In New Zealand, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In South Korea, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In the UAE, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Qatar, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Saudi Arabia, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Oman, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Kuwait, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Bahrain, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Iran, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Iraq, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Jordan, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Lebanon, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Syria, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Yemen, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Algeria, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Tunisia, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Morocco, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Nigeria, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Egypt, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Kenya, it's sold as Levaquin by Johnson & Johnson Ltd. and by other companies like Accord Healthcare Ltd. In Ghana, it's sold as Levaquin by Johnson & Johnson\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"Paracetamol","metadata":{}},{"cell_type":"code","source":"question = \"\"\" which company produces A-One Plus Tablet ?\n\"\"\"\n\n\nFastLanguageModel.for_inference(model) \ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1200,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T10:48:45.590186Z","iopub.execute_input":"2025-04-12T10:48:45.590539Z","iopub.status.idle":"2025-04-12T10:49:08.730517Z","shell.execute_reply.started":"2025-04-12T10:48:45.590515Z","shell.execute_reply":"2025-04-12T10:49:08.729753Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, so I need to figure out which company produces A-One Plus Tablet. First, I'll recall if I know any information about A-One Plus. It sounds familiar, but I'm not exactly sure who manufactures it. I think it's a common medication, so maybe it's produced by a well-known pharmaceutical company. Let me think of some companies I know produce tablets. There's Square Pharmaceuticals, Ambee Pharmaceuticals, ACI Limited, and others. I remember that Square Pharmaceuticals is involved in producing a lot of generic drugs. A-One Plus sounds like a combination of Paracetamol and Caffeine. I think Paracetamol is commonly used for headaches and pain relief. Caffeine is usually included to help with headaches and to make sure that Paracetamol works better. So, A-One Plus is likely a pain relieving tablet. Now, considering the companies that produce Paracetamol tablets, I believe Square Pharmaceuticals is one of them. I think they have a range of products, including pain relief medications. I don't recall the exact name of the manufacturer, but Square Pharmaceuticals is a likely candidate. I should check the brand name to confirm. If it's A-One Plus, then the manufacturer is Square Pharmaceuticals Ltd. I think they are based in Bangladesh and produce a lot of generic drugs. So, putting it all together, I conclude that Square Pharmaceuticals Ltd. produces A-One Plus Tablet.\n</think>\n\nSquare Pharmaceuticals Ltd. produces A-One Plus Tablet. A-One Plus is a combination of Paracetamol and Caffeine, commonly used for headaches and pain relief. Square Pharmaceuticals is a well-known pharmaceutical company based in Bangladesh and produces a wide range of generic drugs.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"question = \"\"\" which company produces A-One Plus Tablet ?\n\"\"\"\n\n\nFastLanguageModel.for_inference(model) \ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1200,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T11:25:00.196318Z","iopub.execute_input":"2025-04-12T11:25:00.196688Z","iopub.status.idle":"2025-04-12T11:25:28.528127Z","shell.execute_reply.started":"2025-04-12T11:25:00.196659Z","shell.execute_reply":"2025-04-12T11:25:28.527399Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nAlright, so the user is asking about a company that produces A-One Plus Tablet. Let me break this down. First, I need to recall if I have any information about A-One Plus. It sounds familiar; I think it's a common medication. I remember that A-One Plus is used for treating certain gastrointestinal issues, maybe diarrhea or dysentery. Now, the user wants to know the manufacturer of this tablet. \n\nI should check my knowledge base. I recall that A-One Plus is manufactured by a well-known pharmaceutical company. I think it's a company based in Bangladesh. Was it Beximco Pharmaceuticals? That rings a bell. I should verify this to be sure. \n\nLet me think about the other companies. There's Square Pharmaceuticals too, but I'm pretty sure Beximco is the one. A-One Plus is a combination of two active ingredients, Loperamide and Simethicone. Loperamide is an antidiarrhoeal medication that reduces the rate of intestinal absorption of water and electrolytes. Simethicone is used to relieve bloating, gas, and indigestion. So, A-One Plus is used to treat acute diarrhea. \n\nWait, is there any other brand produced by another company? I don't recall. It's possible that other companies might have similar products, but A-One Plus specifically is from Beximco. I should make sure I'm not confusing it with other similar medications. \n\nAlso, considering the user's request for the exact manufacturer, I should provide the full name and location of Beximco Pharmaceuticals. Beximco is based in Dhaka, Bangladesh. I think that's all the information the user is looking for. I should present this clearly and concisely.\n</think>\n\nA-One Plus Tablet is produced by Beximco Pharmaceuticals Ltd., a pharmaceutical company based in Dhaka, Bangladesh. A-One Plus is a combination of Loperamide and Simethicone, used to treat acute diarrhea. It is manufactured by Beximco Pharmaceuticals Ltd., located in Dhaka, Bangladesh.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"question = \"\"\" which company produces Ace Pediatric Drops mainly local brand ?\n\"\"\"\n\n\nFastLanguageModel.for_inference(model) \ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1000,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T11:46:34.014006Z","iopub.execute_input":"2025-04-12T11:46:34.014299Z","iopub.status.idle":"2025-04-12T11:47:02.822242Z","shell.execute_reply.started":"2025-04-12T11:46:34.014278Z","shell.execute_reply":"2025-04-12T11:47:02.821307Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, so I need to figure out which company produces Ace Pediatric Drops as a local brand. First, I should probably understand what Ace Pediatric Drops is used for. From what I remember, pediatric drops are often used for cough, cold, and fever. So Ace Pediatric Drops is likely an oral suspension or liquid medicine used to treat these symptoms in children.\n\nNow, the question is about the company that produces it as a local brand. Local brand usually refers to a generic version of a brand product. So, if Ace Pediatric Drops is a brand product, the local version would be produced by a different company. I should check the manufacturer of Ace Pediatric Drops. \n\nI think Ace Pharmaceuticals is the manufacturer of Ace Pediatric Drops. They are a pharmaceutical company based in Bangladesh. They produce various medications, including pediatric drops for cough and cold. Since the user is asking about the local brand, I need to find out which local company produces a generic version of Ace Pediatric Drops.\n\nI should also consider the mode of action and dosage form of Ace Pediatric Drops. It's probably an oral suspension containing cough suppressants and decongestants. The active ingredient might be Paracetamol or other analgesics. The dosage form is liquid for pediatric use.\n\nLocal brands in Bangladesh often have similar ingredients but different dosage forms or strengths. So, companies like Square Pharmaceuticals Ltd., Beximco Pharmaceuticals Ltd., or Unimed Pharmaceuticals Ltd. might produce a generic version of Ace Pediatric Drops. However, without specific information, it's hard to pinpoint the exact company.\n\nI should also consider that sometimes local brands might have slightly different compositions or dosages. Therefore, it's essential to verify with a healthcare professional or the manufacturer for accurate information.\n</think>\n\nAce Pediatric Drops is produced by Ace Pharmaceuticals Ltd., a pharmaceutical company based in Bangladesh. The local brand of Ace Pediatric Drops is produced by various pharmaceutical companies, such as Square Pharmaceuticals Ltd., Beximco Pharmaceuticals Ltd., or Unimed Pharmaceuticals Ltd. These companies may produce generic versions of Ace Pediatric Drops with similar active ingredients and dosage forms. Always consult a healthcare professional or the manufacturer for accurate information.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"question = \"\"\" which company produces Ace Pediatric Drops mainly local brand ?\n\"\"\"\n\n\nFastLanguageModel.for_inference(model) \ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1000,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T11:51:20.607564Z","iopub.execute_input":"2025-04-12T11:51:20.607887Z","iopub.status.idle":"2025-04-12T11:51:54.440699Z","shell.execute_reply.started":"2025-04-12T11:51:20.607863Z","shell.execute_reply":"2025-04-12T11:51:54.439764Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, so I need to figure out which company produces Ace Pediatric Drops, specifically focusing on local brands. First, I should understand what Ace Pediatric Drops are. I don't recall hearing about this specific product before, so I'll start by researching it.\n\nI'll search online for \"Ace Pediatric Drops\" to see if I can find any information about it. Let me check a few search engines to see if there are any reliable sources. Hmm, the first few search results don't provide much information. Maybe it's a newer product or not widely known.\n\nNext, I'll look for any official websites or press releases from pharmaceutical companies that might produce such a product. Let's see... After checking a few companies, I notice that there's no direct mention of Ace Pediatric Drops. This makes me think that it might be a generic or local brand product rather than a well-known international brand.\n\nSince it's a pediatric drops product, it's likely intended for children. The term \"Pediatric Drops\" suggests it's a liquid medication that's easy to administer to children. The product name \"Ace\" might indicate that it's a cough or cold preparation, but without more information, it's hard to say for sure.\n\nGiven that it's a local brand, I should consider companies that primarily operate in specific regions. For example, companies like Square Pharmaceuticals, Beximco Pharmaceuticals, and UniMed UniHealth Pharmaceuticals are prominent in Bangladesh. I'll check if any of these companies have a product by the name of Ace Pediatric Drops.\n\nAfter some more searching, I find that Square Pharmaceuticals does produce a product called \"Ace Pediatric Drops.\" It's a cough syrup containing guaifenesin and pseudoephedrine hydrochloride, used for the relief of symptoms of cough and nasal congestion in pediatric patients. This is a local brand product produced by Square Pharmaceuticals Ltd., Bangladesh.\n\nSo, putting it all together, the company that produces Ace Pediatric Drops, mainly as a local brand, is Square Pharmaceuticals Ltd. They are a prominent pharmaceutical company based in Bangladesh and are known for producing a variety of pharmaceutical products, including pediatric medications.\n</think>\n\nThe company that produces Ace Pediatric Drops, primarily as a local brand, is Square Pharmaceuticals Ltd. This product is a cough syrup containing guaifenesin and pseudoephedrine hydrochloride, designed for the relief of symptoms of cough and nasal congestion in pediatric patients. Square Pharmaceuticals Ltd. is a prominent pharmaceutical company based in Bangladesh.<｜end▁of▁sentence｜>\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"question = \"\"\" I have fever which medicines should I take  ?\n\"\"\"\n\n\nFastLanguageModel.for_inference(model) \ninputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n\noutputs = model.generate(\n    input_ids=inputs.input_ids,\n    attention_mask=inputs.attention_mask,\n    max_new_tokens=1000,\n    use_cache=True,\n)\nresponse = tokenizer.batch_decode(outputs)\nprint(response[0].split(\"### Response:\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T11:53:31.833619Z","iopub.execute_input":"2025-04-12T11:53:31.833939Z","iopub.status.idle":"2025-04-12T11:54:39.621772Z","shell.execute_reply.started":"2025-04-12T11:53:31.833917Z","shell.execute_reply":"2025-04-12T11:54:39.620777Z"}},"outputs":[{"name":"stdout","text":"\n<think>\nOkay, so I have a fever. I'm not exactly sure what's causing it, but I need to get rid of it. I remember that fever is a symptom of many illnesses, like colds, flu, or even something more serious like malaria. But I'm not sure if I have any of those. I think I should try to bring my temperature down because it's making me feel uncomfortable.\n\nI remember my mom used to give me Paracetamol when I had a fever as a kid. It helped reduce the pain and made me feel a bit cooler. Paracetamol is safe, right? It doesn't have too many side effects. But I'm not sure if I should take it now. Maybe it's too late? Wait, no, Paracetamol is available over the counter. I think it's okay to take it unless I have liver problems. I don't have any liver issues, so I guess it's safe.\n\nI also remember hearing about Ibuprofen. My friend's mom uses it sometimes. It's stronger than Paracetamol, I think. But I don't know if I should take Ibuprofen. I don't have any problems with my stomach, so maybe it's okay. I should check the dosage though. I don't want to take too much and hurt myself.\n\nI'm also thinking about taking some rest. When I'm sick, my body heals better if I get enough sleep. I should make sure I'm drinking plenty of fluids too. Maybe some water or oral rehydration solution if I'm dehydrated. I should also eat light foods, like soup or toast, to keep my strength up.\n\nI wonder if I should go see a doctor. My fever is pretty high, and I don't know how long it's been. Maybe I should get it checked out to make sure it's not something serious like malaria or an infection. I don't want to wait too long if it's something that needs treatment.\n\nWait, I should take my temperature to see how high it is. That will help me decide how to treat it. I think a normal temperature is 98.6°F (37°C), so if mine is higher than that, I should be more concerned. I'll get a thermometer and check myself.\n\nIf the fever is very high, I might need to take something stronger than Paracetamol. There's also Acetaminophen, but I think it's the same as Paracetamol. I'm not sure about the dosage for adults. I think adults can take 650-1000 mg every 4-6 hours, but I'm not sure. I should check the label or call the pharmacist to make sure I'm not taking too much.\n\nI should also avoid taking aspirin because it can be hard on the stomach and isn't effective for fevers. Plus, I think aspirin is not recommended for children under 12 years old.\n\nIf I do take Paracetamol or Ibuprofen, I need to make sure I take it with food to reduce stomach irritation. I should also drink some water to help it dissolve better in my system. I should take it at the same time every day so my body gets a steady dose of the medicine.\n\nI'm also thinking about natural remedies. I've heard that lemon juice or honey can help bring down a fever. Maybe I can make a warm drink with some lemon juice and honey in it. I'll try that if I don't feel like taking medicine.\n\nI should also monitor how I'm feeling. If my fever doesn't go down after a few days or if I start feeling worse, I should go see a doctor. They might give me a prescription for something stronger or test me for infections. I don't want to ignore a high fever because it could be a sign of something serious like meningitis or something else that needs immediate treatment.\n\nIn the meantime, I should stay home and avoid contact with other people to prevent spreading whatever I have. I'll make sure to wash my hands regularly and avoid touching my face to reduce the chance of spreading germs.\n\nI think I should also look up some symptoms online to see if there's anything else I should be worried about. Maybe there's a specific infection I have based on my symptoms. But I shouldn't rely solely on online information; if I'm unsure, I should definitely go see a doctor.\n\nOverall, I think the best course of action is to take Paracetamol to reduce my fever and pain, stay hydrated, get some rest, and monitor my symptoms closely. If things don't improve or get worse, I'll go see the doctor.\n</think>\n\nTo address your fever, the following course of action is recommended:\n\n1. **Medication**: Take Paracetamol (650-1000 mg every 4-6 hours) or Ibuprofen (400-800 mg\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"print(type(response))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T12:10:34.253684Z","iopub.execute_input":"2025-04-12T12:10:34.254029Z","iopub.status.idle":"2025-04-12T12:10:34.260259Z","shell.execute_reply.started":"2025-04-12T12:10:34.253999Z","shell.execute_reply":"2025-04-12T12:10:34.259342Z"}},"outputs":[{"name":"stdout","text":"<class 'list'>\n","output_type":"stream"}],"execution_count":50}]}